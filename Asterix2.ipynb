{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep neural networks\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# For data representation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# For handling files\n",
    "import os\n",
    "\n",
    "# For plotting graphs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Gym\n",
    "import gym\n",
    "import random\n",
    "env = gym.make(\"Asterix-v0\")\n",
    "# I have installed pyglet-1.5.11 for it work with BigSur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box([[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]], (210, 160, 3), uint8)\n",
      "Action space: Discrete(9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation space is an RGB picture of size 210x160 whereas the action space is composed of the 18 possible moves from an ATARI controller. The info dictionary contains `ale.lives()` which refers to the number of lives left (but here there is no finite number of lives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Create a simple agent that performs random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 215.0\n"
     ]
    }
   ],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        \n",
    "    def get_action(self, observation):\n",
    "        return random.choice(range(self.action_size))\n",
    "    \n",
    "total_reward=0\n",
    "agent = RandomAgent(env)\n",
    "numberOfEpisodes = 10\n",
    "for steps in range(numberOfEpisodes):\n",
    "    current_obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(current_obs)\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "print(\"Average reward: {}\".format(total_reward/numberOfEpisodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Q-Learning Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "def preprocess_observation(observation):\n",
    "    img = observation[1:192:2, ::2] #This becomes 96, 80,3\n",
    "    img = img.mean(axis=2) #to grayscale (values between 0 and 255)\n",
    "    img = (img - 128).astype(np.int8) # normalize from -128 to 127\n",
    "    return img.reshape(96, 80, 1)\n",
    "\n",
    "plt.imshow(obs)\n",
    "plt.show()\n",
    "plt.imshow(preprocess_observation(obs).reshape(96,80), cmap='gray', vmin=-128, vmax=127)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state / 128.0 # scale pixel intensities to the [-1.0, 1.0] range.\n",
    "    initializer = tf.variance_scaling_initializer()\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=32, \n",
    "                                      kernel_size=8,strides=4,\n",
    "                                      padding=\"SAME\" ,\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_initializer=initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size=4,strides=2,\n",
    "                                      padding=\"SAME\" ,\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_initializer=initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size=3,strides=1,\n",
    "                                      padding=\"SAME\" , \n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_initializer=initializer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1,64 * 12 * 10])\n",
    "        hidden = tf.layers.dense(last_conv_layer_flat,512,\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 kernel_initializer=initializer)\n",
    "        outputs = tf.layers.dense(hidden, env.action_space.n,kernel_initializer=initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "    trainable_vars_by_name = {var.name[len(scope.name):]: var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self, env, learning_rate = 0.001, momentum = 0.95):\n",
    "        self.loss_val = np.infty\n",
    "        self.action_size = env.action_space.n\n",
    "        tf.reset_default_graph()\n",
    "        tf.disable_eager_execution()\n",
    "        self.discount_rate = 0.99\n",
    "        self.checkpoint_path = \"./my_dqn.ckpt\"\n",
    "        self.X_state = tf.placeholder(tf.float32, shape=[None, 96, 80,1])\n",
    "        self.online_q_values, self.online_vars = q_network(self.X_state, name=\"q_networks/online\")\n",
    "        self.target_q_values, self.target_vars = q_network(self.X_state, name=\"q_networks/target\")\n",
    "\n",
    "        #The \"target\" DNN will take the values of the \"online\" DNN\n",
    "        self.copy_ops = [target_var.assign(self.online_vars[var_name]) for var_name, target_var in self.target_vars.items()]\n",
    "        self.copy_online_to_target = tf.group(*self.copy_ops)\n",
    "\n",
    "        #We create the model for training\n",
    "        with tf.variable_scope(\"train\"):\n",
    "            self.X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "            self.q_value = tf.reduce_sum(self.online_q_values * tf.one_hot(self.X_action, self.action_size),axis=1, keepdims=True)\n",
    "            \n",
    "            #If the error is between 0 and 1, \n",
    "            self.error = tf.abs(self.y - self.q_value)\n",
    "            self.clipped_error = tf.clip_by_value(self.error, 0.0, 1.0)\n",
    "            self.linear_error = 2 * (self.error - self.clipped_error)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.clipped_error) + self.linear_error)\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "            self.training_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "        # Saving the session\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        if os.path.isfile(self.checkpoint_path + \".index\"):\n",
    "            self.saver.restore(self.sess, self.checkpoint_path)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(self.copy_online_to_target)\n",
    "        \n",
    "    #---- CHOSSING ACTION ----\n",
    "    def get_action(self,q_values, step):\n",
    "        epsilon = max(0.1, 1)\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.action_size) # random action\n",
    "        else:\n",
    "            return np.argmax(q_values) # optimal action\n",
    "\n",
    "    #---- TRAINING ----\n",
    "    def train(self, state_val, action_val, reward, next_state_val, continues):\n",
    "        # Compute next_qvalues  \n",
    "        next_q_values = self.target_q_values.eval(feed_dict={self.X_state: np.array([next_state_val])})\n",
    "        # Compute best rewards\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        # Compute target values\n",
    "        y_val = reward + continues * self.discount_rate * max_next_q_values\n",
    "        # Train the online DQN\n",
    "        _, self.loss_val = self.sess.run([self.training_op, self.loss], feed_dict={self.X_state: np.array([state_val]), self.X_action: np.array([action_val]), self.y: y_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8. Train your network for $1,000,000$ training steps. Since the training process can take __a lot of time__, save your models every $1000$ training steps. You can choose to only train your model every $4$ frames instead of every frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_dqn.ckpt\n",
      "\tTraining step 9999/10000 (100.0)%\tLoss 0.0017665"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env)  \n",
    "ep_rewards = []\n",
    "total_reward = 0\n",
    "n_steps = 10000  # total number of training steps\n",
    "copy_steps = 5000\n",
    "save_steps = 1000 \n",
    "\n",
    "with agent.sess:\n",
    "    while True:\n",
    "        step = agent.global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "\n",
    "        print(\"\\r\\tTraining step {}/{} ({:.1f})%\\tLoss {:5f}\".format(\n",
    "            step,\n",
    "            n_steps,\n",
    "            step * 100 / n_steps, \n",
    "            agent.loss_val), end=\"\")\n",
    "\n",
    "        if done: # game over, start again\n",
    "            obs = env.reset()\n",
    "            ep_rewards.append(total_reward)\n",
    "            total_reward = 0\n",
    "            state = preprocess_observation(obs)\n",
    "\n",
    "        total_perc = int(step * 100 / n_steps)\n",
    "        \n",
    "        # Online DQN evaluates what to do\n",
    "        q_values = agent.online_q_values.eval(feed_dict={agent.X_state: [state]})\n",
    "        action = agent.get_action(q_values, step)\n",
    "        \n",
    "        # Online DQN plays\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observation(next_obs)\n",
    "        agent.train(state, action, reward, next_state, 1.0 - done)\n",
    "        \n",
    "        env.render()\n",
    "        total_reward+=reward\n",
    "        state = next_state\n",
    "\n",
    "        # Regularly copy the online DQN to the target DQN\n",
    "        if step % copy_steps == 0:\n",
    "            agent.copy_online_to_target.run()\n",
    "\n",
    "        # And save regularly\n",
    "        if step % save_steps == 0:\n",
    "            agent.saver.save(agent.sess, agent.checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Print the evolution of the total number of rewards w.r.t. the episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Rewards:200.0\n",
      "Episode:2 Rewards:200.0\n",
      "Episode:3 Rewards:450.0\n",
      "Episode:4 Rewards:200.0\n",
      "Episode:5 Rewards:100.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = random.choice([0,1,2,3,4,5])\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Rewards:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :-\n",
    "    https://abdn.blackboard.com/ultra/courses/_54210_1/cl/outline  (Tutorial 3)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
